{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, mean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a URL through you can access the Spark UI\n",
    "#get_ipython().system_raw('./ngrok http 4050 &')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the URL\n",
    "#!curl -s http://localhost:4040/api/tunnels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Collecting data - ENEM\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.jars\", \"./path/postgresql-42.7.2.jar\") \\\n",
    "    .config('spark.ui.port', '4050') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing connection and visualizing schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2010'\n",
    "\n",
    "url = \"jdbc:postgresql://localhost:5433/ENEM_Data\"\n",
    "\n",
    "properties = {\n",
    "    \"user\": \"admin\",\n",
    "    \"password\": \"*********\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_connection = spark.read.jdbc(url, \"\\\"Data_years\\\".\\\"2010\\\"\", properties=properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = spark.read.jdbc(url, \"\\\"Data_years\\\".\\\"\" + year + \"\\\"\", properties=properties)\n",
    "df_analysis = spark.read.jdbc(url, \"\\\"Data_years\\\".\\\"Analise_\" + year + \"\\\"\", properties=properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- NU_INSCRICAO: string (nullable = true)\n",
      " |-- NU_ANO: integer (nullable = true)\n",
      " |-- TP_FAIXA_ETARIA: integer (nullable = true)\n",
      " |-- TP_SEXO: string (nullable = true)\n",
      " |-- TP_ESTADO_CIVIL: integer (nullable = true)\n",
      " |-- TP_COR_RACA: integer (nullable = true)\n",
      " |-- TP_ST_CONCLUSAO: integer (nullable = true)\n",
      " |-- TP_ENSINO: integer (nullable = true)\n",
      " |-- CO_MUNICIPIO_ESC: string (nullable = true)\n",
      " |-- NO_MUNICIPIO_ESC: string (nullable = true)\n",
      " |-- CO_UF_ESC: string (nullable = true)\n",
      " |-- SG_UF_ESC: string (nullable = true)\n",
      " |-- TP_DEPENDENCIA_ADM_ESC: integer (nullable = true)\n",
      " |-- TP_LOCALIZACAO_ESC: integer (nullable = true)\n",
      " |-- TP_SIT_FUNC_ESC: integer (nullable = true)\n",
      " |-- IN_CERTIFICADO: boolean (nullable = true)\n",
      " |-- CO_MUNICIPIO_PROVA: string (nullable = true)\n",
      " |-- NO_MUNICIPIO_PROVA: string (nullable = true)\n",
      " |-- CO_UF_PROVA: string (nullable = true)\n",
      " |-- SG_UF_PROVA: string (nullable = true)\n",
      " |-- TP_PRESENCA_CN: integer (nullable = true)\n",
      " |-- TP_PRESENCA_CH: integer (nullable = true)\n",
      " |-- TP_PRESENCA_LC: integer (nullable = true)\n",
      " |-- TP_PRESENCA_MT: integer (nullable = true)\n",
      " |-- CO_PROVA_CN: integer (nullable = true)\n",
      " |-- CO_PROVA_CH: integer (nullable = true)\n",
      " |-- CO_PROVA_LC: integer (nullable = true)\n",
      " |-- CO_PROVA_MT: integer (nullable = true)\n",
      " |-- NU_NOTA_CN: float (nullable = true)\n",
      " |-- NU_NOTA_CH: float (nullable = true)\n",
      " |-- NU_NOTA_LC: float (nullable = true)\n",
      " |-- NU_NOTA_MT: float (nullable = true)\n",
      " |-- TX_RESPOSTAS_CN: string (nullable = true)\n",
      " |-- TX_RESPOSTAS_CH: string (nullable = true)\n",
      " |-- TX_RESPOSTAS_LC: string (nullable = true)\n",
      " |-- TX_RESPOSTAS_MT: string (nullable = true)\n",
      " |-- TP_LINGUA: boolean (nullable = true)\n",
      " |-- TX_GABARITO_CN: string (nullable = true)\n",
      " |-- TX_GABARITO_CH: string (nullable = true)\n",
      " |-- TX_GABARITO_LC: string (nullable = true)\n",
      " |-- TX_GABARITO_MT: string (nullable = true)\n",
      " |-- TP_STATUS_REDACAO: string (nullable = true)\n",
      " |-- NU_NOTA_COMP1: float (nullable = true)\n",
      " |-- NU_NOTA_COMP2: float (nullable = true)\n",
      " |-- NU_NOTA_COMP3: float (nullable = true)\n",
      " |-- NU_NOTA_COMP4: float (nullable = true)\n",
      " |-- NU_NOTA_COMP5: float (nullable = true)\n",
      " |-- NU_NOTA_REDACAO: float (nullable = true)\n",
      " |-- Q01: string (nullable = true)\n",
      " |-- Q02: string (nullable = true)\n",
      " |-- Q03: string (nullable = true)\n",
      " |-- Q04: string (nullable = true)\n",
      " |-- Q05: string (nullable = true)\n",
      " |-- Q06: string (nullable = true)\n",
      " |-- Q07: string (nullable = true)\n",
      " |-- Q08: string (nullable = true)\n",
      " |-- Q09: string (nullable = true)\n",
      " |-- Q10: string (nullable = true)\n",
      " |-- Q11: string (nullable = true)\n",
      " |-- Q12: string (nullable = true)\n",
      " |-- Q13: string (nullable = true)\n",
      " |-- Q14: string (nullable = true)\n",
      " |-- Q15: string (nullable = true)\n",
      " |-- Q16: string (nullable = true)\n",
      " |-- Q17: string (nullable = true)\n",
      " |-- Q18: string (nullable = true)\n",
      " |-- Q19: string (nullable = true)\n",
      " |-- Q20: string (nullable = true)\n",
      " |-- Q21: string (nullable = true)\n",
      " |-- Q22: string (nullable = true)\n",
      " |-- Q23: string (nullable = true)\n",
      " |-- Q24: string (nullable = true)\n",
      " |-- Q25: string (nullable = true)\n",
      " |-- Q26: string (nullable = true)\n",
      " |-- Q27: string (nullable = true)\n",
      " |-- Q28: string (nullable = true)\n",
      " |-- Q29: string (nullable = true)\n",
      " |-- Q30: string (nullable = true)\n",
      " |-- Q31: string (nullable = true)\n",
      " |-- Q32: string (nullable = true)\n",
      " |-- Q33: string (nullable = true)\n",
      " |-- Q34: string (nullable = true)\n",
      " |-- Q35: string (nullable = true)\n",
      " |-- Q36: string (nullable = true)\n",
      " |-- Q37: string (nullable = true)\n",
      " |-- Q38: string (nullable = true)\n",
      " |-- Q39: string (nullable = true)\n",
      " |-- Q40: string (nullable = true)\n",
      " |-- Q41: string (nullable = true)\n",
      " |-- Q42: string (nullable = true)\n",
      " |-- Q43: string (nullable = true)\n",
      " |-- Q44: string (nullable = true)\n",
      " |-- Q45: string (nullable = true)\n",
      " |-- Q46: string (nullable = true)\n",
      " |-- Q47: string (nullable = true)\n",
      " |-- Q48: string (nullable = true)\n",
      " |-- Q49: string (nullable = true)\n",
      " |-- Q50: string (nullable = true)\n",
      " |-- Q51: string (nullable = true)\n",
      " |-- Q52: string (nullable = true)\n",
      " |-- Q53: string (nullable = true)\n",
      " |-- Q54: string (nullable = true)\n",
      " |-- Q55: string (nullable = true)\n",
      " |-- Q56: string (nullable = true)\n",
      " |-- Q57: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_raw.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Ano: integer (nullable = true)\n",
      " |-- Faixa_Etaria: integer (nullable = true)\n",
      " |-- Sexo: string (nullable = true)\n",
      " |-- NU_NOTA_CN: float (nullable = true)\n",
      " |-- NU_NOTA_CH: float (nullable = true)\n",
      " |-- NU_NOTA_LC: float (nullable = true)\n",
      " |-- NU_NOTA_MT: float (nullable = true)\n",
      " |-- NU_NOTA_REDACAO: float (nullable = true)\n",
      " |-- Nota_final: float (nullable = true)\n",
      " |-- Escolaridade_pai: string (nullable = true)\n",
      " |-- Escolaridade_mae: string (nullable = true)\n",
      " |-- Renda_familiar: string (nullable = true)\n",
      " |-- Trabalha_ou_ja: string (nullable = true)\n",
      " |-- Ajudar_despesas_casa: string (nullable = true)\n",
      " |-- Carga_trabalho_semanal: string (nullable = true)\n",
      " |-- Idade_comecou_trabalhar: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_analysis.printSchema()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### But here spark df is in only one partition (standard spark reading for JDBC connection). Let's optimize and speed up the reading from JDBC connection to database, using partitions and parallelizing processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = None\n",
    "df_analysis = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In raw dataframe, going to use column 'CO_PROVA_CN' to make 8 partitions, for there are 8 possible integer values (between 89 and 108), as in the dictionary of the dataset, available to read in the project files. This is the best way to split data and create partitions, because this variable is chosen randomly, and in equal parts, by the test administrators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Else, you can find min and maximum values for partition\n",
    "#df_min_max = spark.read.jdbc(\n",
    "#    url=url,\n",
    "#    table=\"SELECT Min(\\\"NU_NOTA_REDACAO\\\"),Max(\\\"NU_NOTA_REDACAO\\\") FROM \\\"Data_years\\\".\\\"\" + year +\"\\\"\",\n",
    "#    properties=properties,\n",
    "#).collect()\n",
    "#min_value, max_value = df_min_max[0][0], df_min_max[0][1]\n",
    "#\n",
    "#print(f'{min_value}, {max_value}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing minimum and maximum scores, look for corrupted data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Essay scores (expected 0 - 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze min and maximum values\n",
    "df_raw = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .option(\"dbtable\", \"(select \\\"CO_PROVA_CN\\\", \\\"NU_NOTA_REDACAO\\\" from \\\"Data_years\\\".\\\"\" + year + \"\\\")  as subq\") \\\n",
    "    .option(\"numPartitions\",\"8\") \\\n",
    "    .option(\"partitionColumn\", \"\\\"CO_PROVA_CN\\\"\") \\\n",
    "    .option(\"lowerBound\", \"89\") \\\n",
    "    .option(\"upperBound\", \"108\") \\\n",
    "    .option(\"user\", \"admin\") \\\n",
    "    .option(\"password\", \"*********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part = df_raw.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_part.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part.createOrReplaceTempView('NOTA_REDACAO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|min(NU_NOTA_REDACAO)|max(NU_NOTA_REDACAO)|\n",
      "+--------------------+--------------------+\n",
      "|                 0.0|              1000.0|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT Min(NU_NOTA_REDACAO) ,Max(NU_NOTA_REDACAO) FROM NOTA_REDACAO\").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything right here."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ciências da Natureza (expected something in the 0 - 1000 range)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a function to get partitioned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_partitioned(subject, year, url):\n",
    "    # Analyze min and maximum values\n",
    "    df = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .option(\"dbtable\", \"(select \\\"CO_PROVA_CN\\\", \\\"\"+ subject +\"\\\" from \\\"Data_years\\\".\\\"\" + year + \"\\\")  as subq\") \\\n",
    "    .option(\"numPartitions\",\"8\") \\\n",
    "    .option(\"partitionColumn\", \"\\\"CO_PROVA_CN\\\"\") \\\n",
    "    .option(\"lowerBound\", \"89\") \\\n",
    "    .option(\"upperBound\", \"108\") \\\n",
    "    .option(\"user\", \"admin\") \\\n",
    "    .option(\"password\", \"*********\")\n",
    "    df_part = df.load()\n",
    "    return df_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part = load_data_partitioned(\"NU_NOTA_CN\", year, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part.createOrReplaceTempView('NOTA_CN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+\n",
      "|min(NU_NOTA_CN)|max(NU_NOTA_CN)|\n",
      "+---------------+---------------+\n",
      "|          297.3|          844.7|\n",
      "+---------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT Min(NU_NOTA_CN) ,Max(NU_NOTA_CN) FROM NOTA_CN\").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|   avg(NU_NOTA_CN)|\n",
      "+------------------+\n",
      "|485.71208281093135|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT avg(NU_NOTA_CN) FROM NOTA_CN\").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ciências Humanas (expected something in the 0 - 1000 range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part = load_data_partitioned(\"NU_NOTA_CH\", year, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+\n",
      "|min(NU_NOTA_CH)|max(NU_NOTA_CH)|\n",
      "+---------------+---------------+\n",
      "|          265.1|          883.7|\n",
      "+---------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_part.createOrReplaceTempView('NOTA_CH')\n",
    "spark.sql(\"SELECT Min(NU_NOTA_CH) ,Max(NU_NOTA_CH) FROM NOTA_CH\").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------+\n",
      "|round(avg(CAST(NU_NOTA_CH AS DOUBLE)), 2)|\n",
      "+-----------------------------------------+\n",
      "|                                   546.63|\n",
      "+-----------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT ROUND(avg(NU_NOTA_CH),2) FROM NOTA_CH\").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linguagens e Códigos (expected something in the 0 - 1000 range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part = load_data_partitioned(\"NU_NOTA_LC\", year, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+\n",
      "|min(NU_NOTA_LC)|max(NU_NOTA_LC)|\n",
      "+---------------+---------------+\n",
      "|          284.7|          810.1|\n",
      "+---------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_part.createOrReplaceTempView('NOTA_LC')\n",
    "spark.sql(\"SELECT Min(NU_NOTA_LC) ,Max(NU_NOTA_LC) FROM NOTA_LC\").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All scores in range, no corrupted data in these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|Avg_LC|\n",
      "+------+\n",
      "|509.92|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT ROUND(avg(NU_NOTA_LC),2) As Avg_LC FROM NOTA_LC\").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matemática (expected something in the 0 - 1000 range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part = load_data_partitioned(\"NU_NOTA_MT\", year, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+\n",
      "|min(NU_NOTA_MT)|max(NU_NOTA_MT)|\n",
      "+---------------+---------------+\n",
      "|          313.4|          973.2|\n",
      "+---------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_part.createOrReplaceTempView('NOTA_MT')\n",
    "spark.sql(\"SELECT Min(NU_NOTA_MT) ,Max(NU_NOTA_MT) FROM NOTA_MT\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|Avg_MT|\n",
      "+------+\n",
      "|505.09|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT ROUND(avg(NU_NOTA_MT),2) As Avg_MT FROM NOTA_MT\").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All scores from all subjects are within range, which means the data seems very clean and reliable."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing NULL values and count according to absent candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general function for queries using partition\n",
    "def load_query(query, url, partitionColumn = \"CO_PROVA_CN\", numPartitions = \"8\", lowerbound = \"89\", upperbound = \"108\"):\n",
    "    # Analyze min and maximum values\n",
    "    df = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .option(\"dbtable\", query) \\\n",
    "    .option(\"numPartitions\",numPartitions) \\\n",
    "    .option(\"partitionColumn\", \"\\\"\" + partitionColumn + \"\\\"\") \\\n",
    "    .option(\"lowerBound\", lowerbound) \\\n",
    "    .option(\"upperBound\", upperbound) \\\n",
    "    .option(\"user\", \"admin\") \\\n",
    "    .option(\"password\", \"*********\")\n",
    "    df_part = df.load()\n",
    "    return df_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = load_query(\"(select * from \\\"Data_years\\\".\\\"\" + year + \"\\\")  as subq\", url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = df_raw.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4611614\n"
     ]
    }
   ],
   "source": [
    "print(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|   NU_NOTA_REDACAO|\n",
      "+-------+------------------+\n",
      "|  count|           4611612|\n",
      "|   mean|403.19568298460496|\n",
      "| stddev|299.57015603397394|\n",
      "|    min|               0.0|\n",
      "|    max|            1000.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_raw.describe('NU_NOTA_REDACAO').show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only two null values for essay."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find how many missed the test for natural sciences and see if numbers match (0 - missed, 2 - eliminated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1236528"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.filter((col('TP_PRESENCA_CN') == 0) | (col('TP_PRESENCA_CN') == 2)).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1236530"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.filter(\"NU_NOTA_CN is NULL\").count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, there are only two null data for students who were present and atended to the test, not being eliminated."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All these analyzes until here indicates that data is very consistent."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we can continue to the statistical analyzes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical analyzes and queries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Total Score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partition by column 'Faixa_etaria', values in range 1 - 20 according to data description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = load_query(\"(select * from \\\"Data_years\\\".\\\"Analise_\" + year + \"\\\")  as subq\",\n",
    "                          url,\n",
    "                         \"Faixa_Etaria\",\n",
    "                         \"8\",\n",
    "                         \"1\",\n",
    "                         \"20\"\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|  avg(Nota_final)|\n",
      "+-----------------+\n",
      "|524.7814333298339|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_analysis.select(mean(col('Nota_final'))).show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Essay Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|avg(NU_NOTA_REDACAO)|\n",
      "+--------------------+\n",
      "|    596.413035250102|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_raw.filter(col('TP_STATUS_REDACAO') == 'P').select(mean(col('NU_NOTA_REDACAO'))).show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many people registered for the exam"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As obtained before, there were 4,611,614 candidates registered for the exam that year."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many people could be accepted in medicine in a regular university?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medicine is the most competed and difficult course to enter in most universities in Brazil. Minimum score to enter medicine course in UFAM (Federal University of Amazonas) that year was 778.29, according to SISU (a regular minimum score for medicine, not so low, not so high)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "medicine = df_analysis.filter(col('Nota_final') >= 778.29).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 2843 students could enter a medicine course in a regular university that year, out of 4 million.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Only {medicine} students could enter a medicine course in a regular university that year, out of 4 million.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantity of PRESENT students to do the exam\n",
    "size_present = df_raw.filter('''TP_PRESENCA_CN = 1 and \n",
    "                 TP_PRESENCA_CH = 1 and \n",
    "                 TP_PRESENCA_LC = 1 and \n",
    "                 TP_PRESENCA_MT = 1 and \n",
    "                 TP_STATUS_REDACAO = \\'P\\'''').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3105939"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That correspond to 0.0616 % of candidates\n"
     ]
    }
   ],
   "source": [
    "print(\"That correspond to {:.4f} % of candidates\".format(medicine*100/size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And to 0.0915 % of present candidates at exam\n"
     ]
    }
   ],
   "source": [
    "print(\"And to {:.4f} % of present candidates at exam\".format(medicine*100/size_present))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many people could be accepted in course with lowest accepting score?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Courses with lowest accepting score, on average, have passing score of around 400/1000. Considered this number to this study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "easiest_course = df_analysis.filter(col('Nota_final') >= 400).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3041294 students could pass to the easiests courses that year.\n"
     ]
    }
   ],
   "source": [
    "print(f\"{easiest_course} students could pass to the easiests courses that year.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That correspond to 65.95 % of candidates\n"
     ]
    }
   ],
   "source": [
    "print(\"That correspond to {:.2f} % of candidates\".format(easiest_course*100/size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And to 97.9187 % of present candidates at exam\n"
     ]
    }
   ],
   "source": [
    "print(\"And to {:.4f} % of present candidates at exam\".format(easiest_course*100/size_present))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only a curiosity, highest score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis.createOrReplaceTempView('df_analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|max(Nota_final)|\n",
      "+---------------+\n",
      "|          869.2|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT Max(Nota_final) FROM df_analysis\").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many have a good knowledge of their native language (portuguese)?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be analyzed with competence no 1 score of essay, \"Mastery of formal written Portuguese\", in column 'NU_NOTA_COMP1'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.createOrReplaceTempView('df_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+\n",
      "|NU_NOTA_COMP1|  Count|\n",
      "+-------------+-------+\n",
      "|        0-200| 718087|\n",
      "|      200-400| 169614|\n",
      "|      400-600| 475447|\n",
      "|      600-800|1873776|\n",
      "|     800-1000| 598771|\n",
      "|         NULL| 775919|\n",
      "+-------------+-------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' select split.range as \"NU_NOTA_COMP1\", count(*) as \"Count\"\\n from (\\n  select case  \\n    when \"NU_NOTA_COMP1\" between 0 and 40 then \\'0-40\\'\\n    when \"NU_NOTA_COMP1\" between 40.1 and 80 then \\'40-80\\'\\n\\t  when \"NU_NOTA_COMP1\" between 80.1 and 120 then \\'80-120\\'\\n\\t  when \"NU_NOTA_COMP1\" between 120.1 and 160 then \\'120-160\\'\\n\\t  when \"NU_NOTA_COMP1\" between 160.1 and 200 then \\'160-200\\'\\n    when \"NU_NOTA_COMP1\" < 0 or \"NU_NOTA_COMP1\" > 200 then \\'out of range\\'\\n    when \"NU_NOTA_COMP1\" is NULL then \\'NULL\\'\\n\\telse \\'\\' end as range\\n  from df_raw) split\\ngroup by split.range\\nORDER BY split.range '"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    select split.range as NU_NOTA_COMP1, count(*) as Count\n",
    "    from (\n",
    "        select case  \n",
    "          when NU_NOTA_COMP1 between 0 and 200 then '0-200'\n",
    "          when NU_NOTA_COMP1 between 200.1 and 400 then '200-400'\n",
    "\t        when NU_NOTA_COMP1 between 400.1 and 600 then '400-600'\n",
    "\t        when NU_NOTA_COMP1 between 600.1 and 800 then '600-800'\n",
    "\t        when NU_NOTA_COMP1 between 800.1 and 1000 then '800-1000'\n",
    "          when NU_NOTA_COMP1 < 0 or NU_NOTA_COMP1 > 1000 then 'out of range'\n",
    "\t        when NU_NOTA_COMP1 is NULL then 'NULL'\n",
    "\t    else '' end as range\n",
    "  from df_raw) split\n",
    "  group by split.range\n",
    "  ORDER BY split.range\n",
    "''').show()\n",
    "\n",
    "# This is for the other years, where competences are in range 0 - 200 instead of 0 - 1000\n",
    "# select split.range as NU_NOTA_COMP1, count(*) as Count\n",
    "# from (\n",
    "#  select case  \n",
    "#    when NU_NOTA_COMP1 between 0 and 40 then '0-40'\n",
    "#    when NU_NOTA_COMP1 between 40.1 and 80 then '40-80'\n",
    "#\t   when NU_NOTA_COMP1 between 80.1 and 120 then '80-120'\n",
    "#\t   when NU_NOTA_COMP1 between 120.1 and 160 then '120-160'\n",
    "#\t   when NU_NOTA_COMP1 between 160.1 and 200 then '160-200'\n",
    "#    when NU_NOTA_COMP1 < 0 or NU_NOTA_COMP1 > 200 then 'out of range'\n",
    "#    when NU_NOTA_COMP1 is NULL then 'NULL'\n",
    "#\telse '' end as range\n",
    "#  from df_raw) split\n",
    "# group by split.range\n",
    "# ORDER BY split.range \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Income vs Score analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final/Total score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|Avg_score_low_income|\n",
      "+--------------------+\n",
      "|               484.9|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''SELECT ROUND(avg(Nota_final),2) As Avg_score_low_income\n",
    "                FROM df_analysis \n",
    "             WHERE Renda_familiar = 'A' or Renda_familiar = 'H'\n",
    "          '''\n",
    "          ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|Avg_score_high_income|\n",
      "+---------------------+\n",
      "|               609.16|\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''SELECT ROUND(avg(Nota_final),2) As Avg_score_high_income\n",
    "                FROM df_analysis \n",
    "             WHERE Renda_familiar != 'A' \n",
    "                     and Renda_familiar != 'B' \n",
    "                     and Renda_familiar != 'C'\n",
    "                     and Renda_familiar != 'H'\n",
    "          '''\n",
    "          ).show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Essay Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|Avg_score_low_income|\n",
      "+--------------------+\n",
      "|              567.82|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''SELECT ROUND(avg(NU_NOTA_REDACAO),2) As Avg_score_low_income\n",
    "                FROM df_raw \n",
    "             WHERE (Q04 = 'A' or Q04 = 'H')\n",
    "             and TP_STATUS_REDACAO = 'P'\n",
    "          '''\n",
    "          ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|Avg_score_high_income|\n",
      "+---------------------+\n",
      "|               657.47|\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''SELECT ROUND(avg(NU_NOTA_REDACAO),2) As Avg_score_high_income\n",
    "                FROM df_raw\n",
    "             WHERE Q04 != 'A' \n",
    "                     and Q04 != 'B' \n",
    "                     and Q04 != 'C'\n",
    "                     and Q04 != 'H'\n",
    "                     and TP_STATUS_REDACAO = 'P'\n",
    "          '''\n",
    "          ).show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge of native language (portuguese)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|number_of_candidates|\n",
      "+--------------------+\n",
      "|              560996|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    select count(*) As number_of_candidates\n",
    "        from df_raw\n",
    "    where NU_NOTA_COMP1 >= 600 and\n",
    "      (Q04 = 'A' or Q04 = 'H')\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That correspond to only 12.16 % of candidates\n"
     ]
    }
   ],
   "source": [
    "print(\"That correspond to only {:.2f} % of candidates\".format(560996*100/size))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 560 thousand candidates with low income achieved 'reasonably good' score for portuguese knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|number_of_candidates|\n",
      "+--------------------+\n",
      "|             1911551|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    select count(*) As number_of_candidates\n",
    "        from df_raw\n",
    "    where NU_NOTA_COMP1 >= 600 and\n",
    "          Q04 != 'A' and \n",
    "          Q04 != 'H'\n",
    "''').show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And almost 2 million candidates that achieved 'reasonably good' score for portuguese were not low income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "While 61.55 % of present candidates at exam that had 'reasonably good' score for portuguese were not low income\n"
     ]
    }
   ],
   "source": [
    "print(\"While {:.2f} % of present candidates at exam that had 'reasonably good' score for portuguese were not low income\".format(1911551*100/size_present))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many low income candidates could be accepted in medicine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "medicine_income = df_analysis.filter('''Nota_final >= 778.29 and \n",
    "                                (Renda_familiar = 'A' or Renda_familiar = 'H')''').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 51 low income students achieved score to enter a medicine course in a regular university that year, out of 4 million.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Only {medicine_income} low income students achieved score to enter a medicine course in a regular university that year, out of 4 million.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sex vs Score analyzis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final/Total Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----+\n",
      "|avg_final_score|Sexo|\n",
      "+---------------+----+\n",
      "|          519.1|   F|\n",
      "|         533.19|   M|\n",
      "+---------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "select ROUND(avg(Nota_final),2) As avg_final_score, Sexo\n",
    "from df_analysis\n",
    "group by Sexo\n",
    "'''\n",
    ").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Essay score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---+\n",
      "|avg_essay_score|Sex|\n",
      "+---------------+---+\n",
      "|         585.98|  F|\n",
      "|         546.36|  M|\n",
      "+---------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "select ROUND(avg(NU_NOTA_REDACAO),2) As avg_essay_score, TP_SEXO as Sex\n",
    "from df_raw\n",
    "where TP_STATUS_REDACAO = 'P'\n",
    "      or TP_STATUS_REDACAO != 'F'\n",
    "group by TP_SEXO\n",
    "'''\n",
    ").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many have already worked or works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+---+\n",
      "|had_or_have_job_responsabilities|Sex|\n",
      "+--------------------------------+---+\n",
      "|                         1522647|  F|\n",
      "|                         1236892|  M|\n",
      "+--------------------------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "select count(Trabalha_ou_ja) as had_or_have_job_responsabilities, Sexo as Sex\n",
    "from df_analysis\n",
    "where Trabalha_ou_ja = 'S'\n",
    "group by Sexo\n",
    "'''\n",
    ").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, among high income students who have never worked, what is the sex gap in score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+\n",
      "|Total_score|Sex|\n",
      "+-----------+---+\n",
      "|     617.71|  F|\n",
      "|     619.72|  M|\n",
      "+-----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "select ROUND(avg(Nota_final),2) as Total_score, Sexo as Sex\n",
    "from df_analysis\n",
    "    WHERE Renda_familiar != 'A' \n",
    "               and Renda_familiar != 'B' \n",
    "               and Renda_familiar != 'C'\n",
    "               and Renda_familiar != 'H'\n",
    "               and Trabalha_ou_ja = 'N'\n",
    "group by Sexo\n",
    "'''\n",
    ").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the gap between female and male score is much smaller, almost none, with only 2 points of difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "48434fea92bcfa521232aa698a59dbef67c96a63793f88c53e51c3c6eaedc268"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
