{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, mean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a URL through you can access the Spark UI\n",
    "#get_ipython().system_raw('./ngrok http 4050 &')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the URL\n",
    "#!curl -s http://localhost:4040/api/tunnels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Collecting data - ENEM\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.jars\", \"./path/postgresql-42.7.2.jar\") \\\n",
    "    .config('spark.ui.port', '4050') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing connection and visualizing schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2011'\n",
    "\n",
    "url = \"jdbc:postgresql://localhost:5433/ENEM_Data\"\n",
    "\n",
    "properties = {\n",
    "    \"user\": \"admin\",\n",
    "    \"password\": \"*********\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_connection = spark.read.jdbc(url, \"\\\"Data_years\\\".\\\"2010\\\"\", properties=properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = spark.read.jdbc(url, \"\\\"Data_years\\\".\\\"\" + year + \"\\\"\", properties=properties)\n",
    "df_analysis = spark.read.jdbc(url, \"\\\"Data_years\\\".\\\"Analise_\" + year + \"\\\"\", properties=properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- NU_INSCRICAO: string (nullable = true)\n",
      " |-- NU_ANO: integer (nullable = true)\n",
      " |-- TP_FAIXA_ETARIA: integer (nullable = true)\n",
      " |-- TP_SEXO: string (nullable = true)\n",
      " |-- TP_ESTADO_CIVIL: integer (nullable = true)\n",
      " |-- TP_COR_RACA: integer (nullable = true)\n",
      " |-- TP_ST_CONCLUSAO: integer (nullable = true)\n",
      " |-- TP_ANO_CONCLUIU: integer (nullable = true)\n",
      " |-- TP_ESCOLA: integer (nullable = true)\n",
      " |-- TP_ENSINO: integer (nullable = true)\n",
      " |-- CO_MUNICIPIO_ESC: string (nullable = true)\n",
      " |-- NO_MUNICIPIO_ESC: string (nullable = true)\n",
      " |-- CO_UF_ESC: string (nullable = true)\n",
      " |-- SG_UF_ESC: string (nullable = true)\n",
      " |-- TP_DEPENDENCIA_ADM_ESC: integer (nullable = true)\n",
      " |-- TP_LOCALIZACAO_ESC: integer (nullable = true)\n",
      " |-- TP_SIT_FUNC_ESC: integer (nullable = true)\n",
      " |-- IN_CERTIFICADO: boolean (nullable = true)\n",
      " |-- NO_ENTIDADE_CERTIFICACAO: string (nullable = true)\n",
      " |-- CO_UF_ENTIDADE_CERTIFICACAO: string (nullable = true)\n",
      " |-- SG_UF_ENTIDADE_CERTIFICACAO: string (nullable = true)\n",
      " |-- CO_MUNICIPIO_PROVA: string (nullable = true)\n",
      " |-- NO_MUNICIPIO_PROVA: string (nullable = true)\n",
      " |-- CO_UF_PROVA: string (nullable = true)\n",
      " |-- SG_UF_PROVA: string (nullable = true)\n",
      " |-- TP_PRESENCA_CN: integer (nullable = true)\n",
      " |-- TP_PRESENCA_CH: integer (nullable = true)\n",
      " |-- TP_PRESENCA_LC: integer (nullable = true)\n",
      " |-- TP_PRESENCA_MT: integer (nullable = true)\n",
      " |-- CO_PROVA_CN: integer (nullable = true)\n",
      " |-- CO_PROVA_CH: integer (nullable = true)\n",
      " |-- CO_PROVA_LC: integer (nullable = true)\n",
      " |-- CO_PROVA_MT: integer (nullable = true)\n",
      " |-- NU_NOTA_CN: float (nullable = true)\n",
      " |-- NU_NOTA_CH: float (nullable = true)\n",
      " |-- NU_NOTA_LC: float (nullable = true)\n",
      " |-- NU_NOTA_MT: float (nullable = true)\n",
      " |-- TX_RESPOSTAS_CN: string (nullable = true)\n",
      " |-- TX_RESPOSTAS_CH: string (nullable = true)\n",
      " |-- TX_RESPOSTAS_LC: string (nullable = true)\n",
      " |-- TX_RESPOSTAS_MT: string (nullable = true)\n",
      " |-- TP_LINGUA: integer (nullable = true)\n",
      " |-- TX_GABARITO_CN: string (nullable = true)\n",
      " |-- TX_GABARITO_CH: string (nullable = true)\n",
      " |-- TX_GABARITO_LC: string (nullable = true)\n",
      " |-- TX_GABARITO_MT: string (nullable = true)\n",
      " |-- TP_STATUS_REDACAO: string (nullable = true)\n",
      " |-- NU_NOTA_COMP1: float (nullable = true)\n",
      " |-- NU_NOTA_COMP2: float (nullable = true)\n",
      " |-- NU_NOTA_COMP3: float (nullable = true)\n",
      " |-- NU_NOTA_COMP4: float (nullable = true)\n",
      " |-- NU_NOTA_COMP5: float (nullable = true)\n",
      " |-- NU_NOTA_REDACAO: float (nullable = true)\n",
      " |-- Q001: integer (nullable = true)\n",
      " |-- Q002: string (nullable = true)\n",
      " |-- Q003: string (nullable = true)\n",
      " |-- Q004: string (nullable = true)\n",
      " |-- Q005: string (nullable = true)\n",
      " |-- Q006: string (nullable = true)\n",
      " |-- Q007: string (nullable = true)\n",
      " |-- Q008: string (nullable = true)\n",
      " |-- Q009: string (nullable = true)\n",
      " |-- Q010: string (nullable = true)\n",
      " |-- Q011: string (nullable = true)\n",
      " |-- Q012: string (nullable = true)\n",
      " |-- Q013: string (nullable = true)\n",
      " |-- Q014: string (nullable = true)\n",
      " |-- Q015: string (nullable = true)\n",
      " |-- Q016: string (nullable = true)\n",
      " |-- Q017: string (nullable = true)\n",
      " |-- Q018: string (nullable = true)\n",
      " |-- Q019: string (nullable = true)\n",
      " |-- Q020: string (nullable = true)\n",
      " |-- Q021: string (nullable = true)\n",
      " |-- Q022: string (nullable = true)\n",
      " |-- Q023: integer (nullable = true)\n",
      " |-- Q024: string (nullable = true)\n",
      " |-- Q025: string (nullable = true)\n",
      " |-- Q026: string (nullable = true)\n",
      " |-- Q027: string (nullable = true)\n",
      " |-- Q028: string (nullable = true)\n",
      " |-- Q029: string (nullable = true)\n",
      " |-- Q030: string (nullable = true)\n",
      " |-- Q031: string (nullable = true)\n",
      " |-- Q032: string (nullable = true)\n",
      " |-- Q033: string (nullable = true)\n",
      " |-- Q034: string (nullable = true)\n",
      " |-- Q035: string (nullable = true)\n",
      " |-- Q036: string (nullable = true)\n",
      " |-- Q037: string (nullable = true)\n",
      " |-- Q038: string (nullable = true)\n",
      " |-- Q039: string (nullable = true)\n",
      " |-- Q040: string (nullable = true)\n",
      " |-- Q041: string (nullable = true)\n",
      " |-- Q042: string (nullable = true)\n",
      " |-- Q043: string (nullable = true)\n",
      " |-- Q044: string (nullable = true)\n",
      " |-- Q045: string (nullable = true)\n",
      " |-- Q046: string (nullable = true)\n",
      " |-- Q047: string (nullable = true)\n",
      " |-- Q048: string (nullable = true)\n",
      " |-- Q049: string (nullable = true)\n",
      " |-- Q050: string (nullable = true)\n",
      " |-- Q051: string (nullable = true)\n",
      " |-- Q052: string (nullable = true)\n",
      " |-- Q053: string (nullable = true)\n",
      " |-- Q054: string (nullable = true)\n",
      " |-- Q055: string (nullable = true)\n",
      " |-- Q056: string (nullable = true)\n",
      " |-- Q057: string (nullable = true)\n",
      " |-- Q058: string (nullable = true)\n",
      " |-- Q059: string (nullable = true)\n",
      " |-- Q060: string (nullable = true)\n",
      " |-- Q061: string (nullable = true)\n",
      " |-- Q062: string (nullable = true)\n",
      " |-- Q063: string (nullable = true)\n",
      " |-- Q064: string (nullable = true)\n",
      " |-- Q065: string (nullable = true)\n",
      " |-- Q066: string (nullable = true)\n",
      " |-- Q067: string (nullable = true)\n",
      " |-- Q068: string (nullable = true)\n",
      " |-- Q069: string (nullable = true)\n",
      " |-- Q070: string (nullable = true)\n",
      " |-- Q071: string (nullable = true)\n",
      " |-- Q072: string (nullable = true)\n",
      " |-- Q073: string (nullable = true)\n",
      " |-- Q074: string (nullable = true)\n",
      " |-- Q075: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_raw.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Ano: integer (nullable = true)\n",
      " |-- Faixa_Etaria: integer (nullable = true)\n",
      " |-- Sexo: string (nullable = true)\n",
      " |-- NU_NOTA_CN: float (nullable = true)\n",
      " |-- NU_NOTA_CH: float (nullable = true)\n",
      " |-- NU_NOTA_LC: float (nullable = true)\n",
      " |-- NU_NOTA_MT: float (nullable = true)\n",
      " |-- NU_NOTA_REDACAO: float (nullable = true)\n",
      " |-- Nota_final: float (nullable = true)\n",
      " |-- Escolaridade_pai: string (nullable = true)\n",
      " |-- Escolaridade_mae: string (nullable = true)\n",
      " |-- Renda_familiar: string (nullable = true)\n",
      " |-- Trabalha_ou_ja: string (nullable = true)\n",
      " |-- Ajudar_despesas_casa: string (nullable = true)\n",
      " |-- Carga_trabalho_semanal: string (nullable = true)\n",
      " |-- Idade_comecou_trabalhar: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_analysis.printSchema()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### But here spark df is in only one partition (standard spark reading for JDBC connection). Let's optimize and speed up the reading from JDBC connection to database, using partitions and parallelizing processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = None\n",
    "df_analysis = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In raw dataframe, going to use column 'CO_PROVA_CN' to make 8 partitions, for there are 8 possible integer values (between 89 and 108), as in the dictionary of the dataset, available to read in the project files. This is the best way to split data and create partitions, because this variable is chosen randomly, and in equal parts, by the test administrators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Else, you can find min and maximum values for partition\n",
    "#df_min_max = spark.read.jdbc(\n",
    "#    url=url,\n",
    "#    table=\"SELECT Min(\\\"NU_NOTA_REDACAO\\\"),Max(\\\"NU_NOTA_REDACAO\\\") FROM \\\"Data_years\\\".\\\"\" + year +\"\\\"\",\n",
    "#    properties=properties,\n",
    "#).collect()\n",
    "#min_value, max_value = df_min_max[0][0], df_min_max[0][1]\n",
    "#\n",
    "#print(f'{min_value}, {max_value}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing minimum and maximum scores, look for corrupted data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Essay scores (expected 0 - 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze min and maximum values\n",
    "df_raw = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .option(\"dbtable\", \"(select \\\"CO_PROVA_CN\\\", \\\"NU_NOTA_REDACAO\\\" from \\\"Data_years\\\".\\\"\" + year + \"\\\")  as subq\") \\\n",
    "    .option(\"numPartitions\",\"8\") \\\n",
    "    .option(\"partitionColumn\", \"\\\"CO_PROVA_CN\\\"\") \\\n",
    "    .option(\"lowerBound\", \"89\") \\\n",
    "    .option(\"upperBound\", \"108\") \\\n",
    "    .option(\"user\", \"admin\") \\\n",
    "    .option(\"password\", \"*********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part = df_raw.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_part.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part.createOrReplaceTempView('NOTA_REDACAO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|min(NU_NOTA_REDACAO)|max(NU_NOTA_REDACAO)|\n",
      "+--------------------+--------------------+\n",
      "|                 0.0|              1000.0|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT Min(NU_NOTA_REDACAO) ,Max(NU_NOTA_REDACAO) FROM NOTA_REDACAO\").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything right here."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ciências da Natureza (expected something in the 0 - 1000 range)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a function to get partitioned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_partitioned(subject, year, url):\n",
    "    # Analyze min and maximum values\n",
    "    df = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .option(\"dbtable\", \"(select \\\"CO_PROVA_CN\\\", \\\"\"+ subject +\"\\\" from \\\"Data_years\\\".\\\"\" + year + \"\\\")  as subq\") \\\n",
    "    .option(\"numPartitions\",\"8\") \\\n",
    "    .option(\"partitionColumn\", \"\\\"CO_PROVA_CN\\\"\") \\\n",
    "    .option(\"lowerBound\", \"89\") \\\n",
    "    .option(\"upperBound\", \"108\") \\\n",
    "    .option(\"user\", \"admin\") \\\n",
    "    .option(\"password\", \"*********\")\n",
    "    df_part = df.load()\n",
    "    return df_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part = load_data_partitioned(\"NU_NOTA_CN\", year, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part.createOrReplaceTempView('NOTA_CN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+\n",
      "|min(NU_NOTA_CN)|max(NU_NOTA_CN)|\n",
      "+---------------+---------------+\n",
      "|          265.0|          867.2|\n",
      "+---------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT Min(NU_NOTA_CN) ,Max(NU_NOTA_CN) FROM NOTA_CN\").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|  avg(NU_NOTA_CN)|\n",
      "+-----------------+\n",
      "|486.5187887107547|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT avg(NU_NOTA_CN) FROM NOTA_CN\").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ciências Humanas (expected something in the 0 - 1000 range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part = load_data_partitioned(\"NU_NOTA_CH\", year, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+\n",
      "|min(NU_NOTA_CH)|max(NU_NOTA_CH)|\n",
      "+---------------+---------------+\n",
      "|          252.9|          793.1|\n",
      "+---------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_part.createOrReplaceTempView('NOTA_CH')\n",
    "spark.sql(\"SELECT Min(NU_NOTA_CH) ,Max(NU_NOTA_CH) FROM NOTA_CH\").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------+\n",
      "|round(avg(CAST(NU_NOTA_CH AS DOUBLE)), 2)|\n",
      "+-----------------------------------------+\n",
      "|                                   498.77|\n",
      "+-----------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT ROUND(avg(NU_NOTA_CH),2) FROM NOTA_CH\").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linguagens e Códigos (expected something in the 0 - 1000 range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part = load_data_partitioned(\"NU_NOTA_LC\", year, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+\n",
      "|min(NU_NOTA_LC)|max(NU_NOTA_LC)|\n",
      "+---------------+---------------+\n",
      "|          301.2|          795.5|\n",
      "+---------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_part.createOrReplaceTempView('NOTA_LC')\n",
    "spark.sql(\"SELECT Min(NU_NOTA_LC) ,Max(NU_NOTA_LC) FROM NOTA_LC\").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All scores in range, no corrupted data in these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|Avg_LC|\n",
      "+------+\n",
      "|541.18|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT ROUND(avg(NU_NOTA_LC),2) As Avg_LC FROM NOTA_LC\").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matemática (expected something in the 0 - 1000 range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part = load_data_partitioned(\"NU_NOTA_MT\", year, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+\n",
      "|min(NU_NOTA_MT)|max(NU_NOTA_MT)|\n",
      "+---------------+---------------+\n",
      "|          321.6|          953.0|\n",
      "+---------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_part.createOrReplaceTempView('NOTA_MT')\n",
    "spark.sql(\"SELECT Min(NU_NOTA_MT) ,Max(NU_NOTA_MT) FROM NOTA_MT\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|Avg_MT|\n",
      "+------+\n",
      "|543.14|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT ROUND(avg(NU_NOTA_MT),2) As Avg_MT FROM NOTA_MT\").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All scores from all subjects are within range, which means the data seems very clean and reliable."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing NULL values and count according to absent candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general function for queries using partition\n",
    "def load_query(query, url, partitionColumn = \"CO_PROVA_CN\", numPartitions = \"8\", lowerbound = \"89\", upperbound = \"108\"):\n",
    "    # Analyze min and maximum values\n",
    "    df = spark.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", url) \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .option(\"dbtable\", query) \\\n",
    "    .option(\"numPartitions\",numPartitions) \\\n",
    "    .option(\"partitionColumn\", \"\\\"\" + partitionColumn + \"\\\"\") \\\n",
    "    .option(\"lowerBound\", lowerbound) \\\n",
    "    .option(\"upperBound\", upperbound) \\\n",
    "    .option(\"user\", \"admin\") \\\n",
    "    .option(\"password\", \"*********\")\n",
    "    df_part = df.load()\n",
    "    return df_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = load_query(\"(select * from \\\"Data_years\\\".\\\"\" + year + \"\\\")  as subq\", url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = df_raw.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "631259\n"
     ]
    }
   ],
   "source": [
    "print(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|  NU_NOTA_REDACAO|\n",
      "+-------+-----------------+\n",
      "|  count|           631259|\n",
      "|   mean|433.0645627222008|\n",
      "| stddev| 277.162355926838|\n",
      "|    min|              0.0|\n",
      "|    max|           1000.0|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_raw.describe('NU_NOTA_REDACAO').show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no null values for essay."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find how many missed the test for natural sciences and see if numbers match (0 - missed, 2 - eliminated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132737"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.filter((col('TP_PRESENCA_CN') == 0) | (col('TP_PRESENCA_CN') == 2)).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132737"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.filter(\"NU_NOTA_CN is NULL\").count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, there are only two null data for students who were present and atended to the test, not being eliminated."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All these analyzes until here indicates that data is very consistent."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we can continue to the statistical analyzes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical analyzes and queries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Total Score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partition by column 'Faixa_etaria', values in range 1 - 20 according to data description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = load_query(\"(select * from \\\"Data_years\\\".\\\"Analise_\" + year + \"\\\")  as subq\",\n",
    "                          url,\n",
    "                         \"Faixa_Etaria\",\n",
    "                         \"8\",\n",
    "                         \"1\",\n",
    "                         \"20\"\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|  avg(Nota_final)|\n",
      "+-----------------+\n",
      "|526.6112369999335|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_analysis.select(mean(col('Nota_final'))).show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Essay Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|avg(NU_NOTA_REDACAO)|\n",
      "+--------------------+\n",
      "|   573.8284760707835|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_raw.filter(col('TP_STATUS_REDACAO') == 'P').select(mean(col('NU_NOTA_REDACAO'))).show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many people registered for the exam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### As obtained before, there were 631259 candidates registered for the exam that year."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown as md\n",
    "md(f\"#### As obtained before, there were {size} candidates registered for the exam that year.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many people could be accepted in medicine in a regular university?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medicine is the most competed and difficult course to enter in most universities in Brazil. Minimum score to enter medicine course in UFAM (Federal University of Amazonas) that year was 771,65, according to SISU (a regular minimum score for medicine, not so low, not so high)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "medicine = df_analysis.filter(col('Nota_final') >= 771.65).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 673 students could enter a medicine course in a regular university that year, out of 631259.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Only {medicine} students could enter a medicine course in a regular university that year, out of {size}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantity of PRESENT students to do the exam\n",
    "size_present = df_raw.filter('''TP_PRESENCA_CN = 1 and \n",
    "                 TP_PRESENCA_CH = 1 and \n",
    "                 TP_PRESENCA_LC = 1 and \n",
    "                 TP_PRESENCA_MT = 1 and \n",
    "                 TP_STATUS_REDACAO = \\'P\\'''').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "475005"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That correspond to 0.1066 % of candidates\n"
     ]
    }
   ],
   "source": [
    "print(\"That correspond to {:.4f} % of candidates\".format(medicine*100/size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And to 0.1417 % of present candidates at exam\n"
     ]
    }
   ],
   "source": [
    "print(\"And to {:.4f} % of present candidates at exam\".format(medicine*100/size_present))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many people could be accepted in course with lowest accepting score?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Courses with lowest accepting score, on average, have passing score of around 400/1000. Considered this number to this study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "easiest_course = df_analysis.filter(col('Nota_final') >= 400).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "458434 students could pass to the easiests courses that year.\n"
     ]
    }
   ],
   "source": [
    "print(f\"{easiest_course} students could pass to the easiests courses that year.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That correspond to 72.62 % of candidates\n"
     ]
    }
   ],
   "source": [
    "print(\"That correspond to {:.2f} % of candidates\".format(easiest_course*100/size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And to 96.5114 % of present candidates at exam\n"
     ]
    }
   ],
   "source": [
    "print(\"And to {:.4f} % of present candidates at exam\".format(easiest_course*100/size_present))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only a curiosity, highest score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis.createOrReplaceTempView('df_analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|max(Nota_final)|\n",
      "+---------------+\n",
      "|         846.42|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT Max(Nota_final) FROM df_analysis\").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many have a good knowledge of their native language (portuguese)?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be analyzed with competence no 1 score of essay, \"Mastery of formal written Portuguese\", in column 'NU_NOTA_COMP1'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.createOrReplaceTempView('df_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+\n",
      "|NU_NOTA_COMP1| Count|\n",
      "+-------------+------+\n",
      "|         0-40|  2261|\n",
      "|      120-160|189753|\n",
      "|      160-200| 40091|\n",
      "|        40-80| 37003|\n",
      "|       80-120|207299|\n",
      "+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This is for the other years, where competences are in range 0 - 200 instead of 0 - 1000\n",
    "spark.sql(\"\"\"select split.range as NU_NOTA_COMP1, count(*) as Count\n",
    " from (\n",
    "  select case  \n",
    "    when NU_NOTA_COMP1 between 0 and 40 then '0-40'\n",
    "    when NU_NOTA_COMP1 between 40.1 and 80 then '40-80'\n",
    "\t   when NU_NOTA_COMP1 between 80.1 and 120 then '80-120'\n",
    "\t   when NU_NOTA_COMP1 between 120.1 and 160 then '120-160'\n",
    "\t   when NU_NOTA_COMP1 between 160.1 and 200 then '160-200'\n",
    "    when NU_NOTA_COMP1 < 0 or NU_NOTA_COMP1 > 200 then 'out of range'\n",
    "    when NU_NOTA_COMP1 is NULL then 'NULL'\n",
    "\telse '' end as range\n",
    "  from df_raw\n",
    "  where TP_STATUS_REDACAO = 'P') split\n",
    " group by split.range\n",
    " ORDER BY split.range \"\"\").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Income vs Score analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final/Total score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|Avg_score_low_income|\n",
      "+--------------------+\n",
      "|              482.27|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''SELECT ROUND(avg(Nota_final),2) As Avg_score_low_income\n",
    "                FROM df_analysis \n",
    "             WHERE Renda_familiar = 'A' or Renda_familiar = 'B'\n",
    "          '''\n",
    "          ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|Avg_score_high_income|\n",
      "+---------------------+\n",
      "|               601.12|\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''SELECT ROUND(avg(Nota_final),2) As Avg_score_high_income\n",
    "                FROM df_analysis \n",
    "             WHERE Renda_familiar != 'A' \n",
    "                     and Renda_familiar != 'B' \n",
    "                     and Renda_familiar != 'C'\n",
    "                     and Renda_familiar != 'D'\n",
    "                     and Renda_familiar != 'E'\n",
    "          '''\n",
    "          ).show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Essay Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|Avg_score_low_income|\n",
      "+--------------------+\n",
      "|              533.56|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''SELECT ROUND(avg(NU_NOTA_REDACAO),2) As Avg_score_low_income\n",
    "                FROM df_raw \n",
    "             WHERE (Q004 = 'A' or Q004 = 'B')\n",
    "             and TP_STATUS_REDACAO = 'P'\n",
    "          '''\n",
    "          ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|Avg_score_high_income|\n",
      "+---------------------+\n",
      "|                643.9|\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''SELECT ROUND(avg(NU_NOTA_REDACAO),2) As Avg_score_high_income\n",
    "                FROM df_raw\n",
    "             WHERE Q004 != 'A' \n",
    "                     and Q004 != 'B' \n",
    "                     and Q004 != 'C'\n",
    "                     and Q004 != 'D'\n",
    "                     and Q004 != 'E'\n",
    "                     and TP_STATUS_REDACAO = 'P'\n",
    "          '''\n",
    "          ).show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge of native language (portuguese)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|number_of_candidates|\n",
      "+--------------------+\n",
      "|               53518|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    select count(*) As number_of_candidates\n",
    "        from df_raw\n",
    "    where NU_NOTA_COMP1 >= 120 and\n",
    "      (Q004 = 'A' or Q004 = 'B')\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That correspond to only 8.48 % of candidates\n"
     ]
    }
   ],
   "source": [
    "print(\"That correspond to only {:.2f} % of candidates\".format(53518*100/size))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 53 thousand candidates with low income achieved 'reasonably good' score for portuguese knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|number_of_candidates|\n",
      "+--------------------+\n",
      "|              317562|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    select count(*) As number_of_candidates\n",
    "        from df_raw\n",
    "    where NU_NOTA_COMP1 >= 120 and\n",
    "          Q004 != 'A' and Q004 != 'B'\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "While 66.85 % of present candidates at exam that had 'reasonably good' score for portuguese were not low income\n"
     ]
    }
   ],
   "source": [
    "print(\"While {:.2f} % of present candidates at exam that had 'reasonably good' score for portuguese were not low income\".format(317562*100/size_present))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many low income candidates could be accepted in medicine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "medicine_income = df_analysis.filter('''Nota_final >= 771.65 and \n",
    "                                (Renda_familiar = 'A' or Renda_familiar = 'B')''').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 12 low income students achieved score to enter a medicine course in a regular university that year.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Only {medicine_income} low income students achieved score to enter a medicine course in a regular university that year.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sex vs Score analyzis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final/Total Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----+\n",
      "|avg_final_score|Sexo|\n",
      "+---------------+----+\n",
      "|         521.32|   F|\n",
      "|         534.67|   M|\n",
      "+---------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "select ROUND(avg(Nota_final),2) As avg_final_score, Sexo\n",
    "from df_analysis\n",
    "group by Sexo\n",
    "'''\n",
    ").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Essay score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---+\n",
      "|avg_essay_score|Sex|\n",
      "+---------------+---+\n",
      "|          573.1|  F|\n",
      "|         540.57|  M|\n",
      "+---------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "select ROUND(avg(NU_NOTA_REDACAO),2) As avg_essay_score, TP_SEXO as Sex\n",
    "from df_raw\n",
    "where TP_STATUS_REDACAO = 'P'\n",
    "      or TP_STATUS_REDACAO != 'F'\n",
    "group by TP_SEXO\n",
    "'''\n",
    ").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many have already worked or works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+---+\n",
      "|had_or_have_job_responsabilities|Sex|\n",
      "+--------------------------------+---+\n",
      "|                          186133|  F|\n",
      "|                          151513|  M|\n",
      "+--------------------------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "select count(Trabalha_ou_ja) as had_or_have_job_responsabilities, Sexo as Sex\n",
    "from df_analysis\n",
    "where Trabalha_ou_ja = 'S'\n",
    "group by Sexo\n",
    "'''\n",
    ").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, among high income students who have never worked, what is the sex gap in score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+\n",
      "|Total_score|Sex|\n",
      "+-----------+---+\n",
      "|     607.16|  F|\n",
      "|      614.3|  M|\n",
      "+-----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "select ROUND(avg(Nota_final),2) as Total_score, Sexo as Sex\n",
    "from df_analysis\n",
    "    WHERE Renda_familiar != 'A' \n",
    "            and Renda_familiar != 'B' \n",
    "            and Renda_familiar != 'C'\n",
    "            and Renda_familiar != 'D'\n",
    "            and Renda_familiar != 'E'\n",
    "            and Trabalha_ou_ja = 'N'\n",
    "group by Sexo\n",
    "'''\n",
    ").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the gap between female and male score is musch smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "48434fea92bcfa521232aa698a59dbef67c96a63793f88c53e51c3c6eaedc268"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
